{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "ch10.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU8g3OY57W2B",
        "colab_type": "code",
        "outputId": "5ce57542-73b2-4051-b585-a768e8fd6ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leKq6Cxk8eOU",
        "colab_type": "code",
        "outputId": "22485ae3-84d6-45ae-aaff-72ad160184d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install janome"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 29.4MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.3.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xnZ-F_x76B1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import torch\n",
        "import spacy\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from janome.tokenizer import Tokenizer\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfsjGQc36B1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j_t = Tokenizer()\n",
        "def tokenizer_ja(text): \n",
        "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "def tokenizer_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "TEXT_ja = data.Field(tokenize=tokenizer_ja,\n",
        "                            lower=True)\n",
        "TEXT_en = data.Field(tokenize=tokenizer_en,\n",
        "                            lower=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXIlC7Xk6B1a",
        "colab_type": "code",
        "outputId": "4ac2d66a-0f25-4e6b-b2be-abca7eaf84be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#90\n",
        "def dataloader(path, tokenizer):\n",
        "    with open(path) as f:\n",
        "        result=[]\n",
        "        for line in tqdm(f):\n",
        "            result.append(tokenizer(line.strip()))\n",
        "    return result\n",
        "\n",
        "train_en = dataloader(\"/content/drive/My Drive/orig/kyoto-train.en\", tokenizer=tokenizer_en)\n",
        "#trainの_jaはtokenizerの処理が遅いため、csvに書き出したものを読み込む\n",
        "with open('/content/drive/My Drive/orig/kyoto-train-tokenized.csv') as f:\n",
        "  reader = csv.reader(f)\n",
        "  train_ja = [row for row in reader]\n",
        "\n",
        "#train_ja  = dataloader(\"/content/drive/My Drive/orig/kyoto-train.ja\", tokenizer=tokenizer_ja)\n",
        "valid_en = dataloader(\"/content/drive/My Drive/orig/kyoto-dev.en\", tokenizer=tokenizer_en)\n",
        "valid_ja  = dataloader(\"/content/drive/My Drive/orig/kyoto-dev.ja\", tokenizer=tokenizer_ja)\n",
        "test_en = dataloader(\"/content/drive/My Drive/orig/kyoto-test.en\", tokenizer=tokenizer_en)\n",
        "test_ja  = dataloader(\"/content/drive/My Drive/orig/kyoto-test.ja\", tokenizer=tokenizer_ja)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440288it [02:29, 2939.04it/s]\n",
            "1166it [00:00, 1488.84it/s]\n",
            "1166it [00:04, 291.42it/s]\n",
            "1160it [00:00, 1414.89it/s]\n",
            "1160it [00:03, 352.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6WbzZGP6B1f",
        "colab_type": "text"
      },
      "source": [
        "train, valid, test = data.TabularDataset.splits(\n",
        "        path='../data/kftt-data-1.0/data/orig/',\n",
        "        train          ='kyoto-train.tsv',\n",
        "        validation =\"kyoto-dev.tsv\",\n",
        "        test           = \"kyoto-test.tsv\", format='tsv',\n",
        "        fields=[('ja', TEXT_ja),('en', TEXT_en)])\n",
        "\n",
        "TEXT_ja.build_vocab(train, min_freq=2)\n",
        "TEXT_en.build_vocab(train, min_freq=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJaJfpzx6B1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dict(df):\n",
        "    frequency = defaultdict(int)\n",
        "    for text in df:\n",
        "        for token in text:\n",
        "            frequency[token] += 1\n",
        "    return frequency\n",
        "\n",
        "\n",
        "def make_id_dict(dic):\n",
        "    id_dict={}\n",
        "    for i , (k,v) in enumerate(sorted(dic.items(), key=lambda x : -x[1])):\n",
        "    #軽量化のためv>=5に。本来はv>=2\n",
        "        if v>=2:\n",
        "            id_dict[k]=i+1\n",
        "        else:\n",
        "            id_dict[k]=0\n",
        "    return id_dict\n",
        "\n",
        "word_dict_en=make_id_dict(make_dict(train_en))\n",
        "word_dict_ja=make_id_dict(make_dict(train_ja))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkWTcN8h6B1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_to_id(batch, id_dic, dim):\n",
        "    #バッチごとに通す\n",
        "    \n",
        "    result=torch.zeros([len(batch), dim], dtype=torch.long) \n",
        "    for i, sentence in enumerate(batch):\n",
        "        for u, word in enumerate(sentence):\n",
        "            try:\n",
        "                result[i, u]=id_dic[word]\n",
        "            except:\n",
        "                continue\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "3qTGoNFp6B1n",
        "colab_type": "text"
      },
      "source": [
        "#fieldがない行を削除\n",
        "for i in range(len(train.examples)):\n",
        "    try:\n",
        "        train.examples[-i-1].en\n",
        "        train.examples[-i-1].ja\n",
        "    except:\n",
        "        train.examples.pop(-i-1)\n",
        "        print(\"delete number.\",i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "ecmBamQn6B1s",
        "colab_type": "text"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator= data.Iterator.splits(\n",
        "    datasets=(train, valid, test),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort=False,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1KA-Ld6B1t",
        "colab_type": "code",
        "outputId": "7a953061-6995-453a-e8a1-e709ec000da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#91#92#93\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(word_dict_ja)\n",
        "OUTPUT_DIM = len(word_dict_en)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 50,516,725 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Swg3IR6B1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PAD_IDX = TEXT_ja.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fOj0f_0R6B11",
        "colab_type": "code",
        "outputId": "ee359514-d132-4232-8b96-d664e76cd1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def train(model,X_train, y_train, optimizer,\n",
        "          criterion,clip: float):\n",
        "    \n",
        "    batch_size= 16\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for idx in tqdm(range(0, len(X_train), batch_size)):\n",
        "        \n",
        "        batch_X = X_train[idx : idx+batch_size if idx+batch_size<=len(X_train) else len(X_train)]\n",
        "        batch_y = y_train[idx : idx+batch_size if idx+batch_size<=len(X_train) else len(X_train)]\n",
        "        dim= max(max([len(i) for i in batch_X]), max([len(i) for i in batch_y]))\n",
        "        src = word_to_id(batch_X, word_dict_ja, dim)\n",
        "        trg = word_to_id(batch_y, word_dict_en, dim)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src.cuda(), trg.cuda())\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg.cuda())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / (len(X_train)//batch_size)\n",
        "\n",
        "\n",
        "def evaluate(model, X_train, y_train,criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    batch_size= 16\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for idx in tqdm(range(0, len(X_train), batch_size)):\n",
        "            batch_X = X_train[idx : idx+batch_size if idx+batch_size<=len(X_train) else len(X_train)]\n",
        "            batch_y = y_train[idx : idx+batch_size if idx+batch_size<=len(X_train) else len(X_train)]\n",
        "            dim= max(max([len(i) for i in batch_X]), max([len(i) for i in batch_y]))\n",
        "            src = word_to_id(batch_X, word_dict_ja, dim)\n",
        "            trg = word_to_id(batch_y, word_dict_en, dim)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            output = model(src.cuda() , trg.cuda(), 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg.cuda())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / (len(X_train)//batch_size)\n",
        "\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_ja,train_en, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_ja, valid_en, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "\n",
        "\n",
        "test_loss = evaluate(model, test_ja, test_en, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/625 [00:00<10:14,  1.02it/s]\u001b[A\n",
            "  0%|          | 2/625 [00:01<09:44,  1.07it/s]\u001b[A\n",
            "  0%|          | 3/625 [00:02<09:14,  1.12it/s]\u001b[A\n",
            "  1%|          | 4/625 [00:03<08:50,  1.17it/s]\u001b[A\n",
            "  1%|          | 5/625 [00:04<08:51,  1.17it/s]\u001b[A\n",
            "  1%|          | 6/625 [00:05<08:52,  1.16it/s]\u001b[A\n",
            "  1%|          | 7/625 [00:06<09:01,  1.14it/s]\u001b[A\n",
            "  1%|▏         | 8/625 [00:07<09:59,  1.03it/s]\u001b[A\n",
            "  1%|▏         | 9/625 [00:07<09:25,  1.09it/s]\u001b[A\n",
            "  2%|▏         | 10/625 [00:08<09:34,  1.07it/s]\u001b[A\n",
            "  2%|▏         | 11/625 [00:10<12:02,  1.18s/it]\u001b[A\n",
            "  2%|▏         | 12/625 [00:12<12:58,  1.27s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7aa80cc09806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ja\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_en\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ja\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7aa80cc09806>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.13 GiB (GPU 0; 11.17 GiB total capacity; 7.29 GiB already allocated; 450.81 MiB free; 10.42 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fcff5a04536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7fcff5c4df1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7fcff5c4ef9e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7fcff87fafd5 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf9310b (0x7fcff6df310b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfdc9f7 (0x7fcff6e3c9f7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1075389 (0x7fd02e787389 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10756c7 (0x7fd02e7876c7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe2165e (0x7fd02e53365e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7fd02e539f50 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1134321 (0x7fd02e846321 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1187623 (0x7fd02e899623 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x28c7d12 (0x7fcff8727d12 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7fcff873c729 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7fcff87284a9 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #15: <unknown function> + 0xf9dd90 (0x7fcff6dfdd90 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0x10c5ad6 (0x7fd02e7d7ad6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x2ca99fc (0x7fd0303bb9fc in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #18: <unknown function> + 0x10c5ad6 (0x7fd02e7d7ad6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7fd02ffb7869 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89c05 (0x7fd03049bc05 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fd030498f03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fd030499ce2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fd030492359 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fd03cbd1378 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xbd6df (0x7fd0618006df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #26: <unknown function> + 0x76db (0x7fd0628e26db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x3f (0x7fd062c1b88f in /lib/x86_64-linux-gnu/libc.so.6)\n"
          ]
        }
      ]
    }
  ]
}